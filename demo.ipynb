{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GboZnz_Zw5nr"
      },
      "source": [
        "# Dependency install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B01ms5RVnHdL",
        "outputId": "cf4e6b08-7f51-490e-ac1c-b7b8070f5d45"
      },
      "outputs": [],
      "source": [
        "!pip install roboflow -q\n",
        "!pip install ultralytics==8.0.196 -q\n",
        "!pip install wget -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyiyCKMBxr8g"
      },
      "source": [
        "# Dependency Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "mW-mLJujfB48"
      },
      "outputs": [],
      "source": [
        "#from roboflow import Roboflow\n",
        "from ultralytics import YOLO\n",
        "import json\n",
        "import shutil\n",
        "import gdown\n",
        "import requests\n",
        "# import yaml\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import random\n",
        "from io import BytesIO\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import wget\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "# from google.colab import drive\n",
        "import tensorflow as tf\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Olu9QKJrxthx"
      },
      "source": [
        "# Dataset retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMd-KbPoEBq3"
      },
      "source": [
        "There are 2 options that can be taken\n",
        "\n",
        "1.   Download it from the TACO dataset's JSON\n",
        "2.   Download from google drive (latest dataset update: 13 Feb 2023)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01pWDYnn-iOU"
      },
      "source": [
        "## Download from json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "a7mZWAALlfX-",
        "outputId": "57aa94df-1869-44d8-b343-da8ceb9f0c69"
      },
      "outputs": [],
      "source": [
        "id = \"11tzOy41twUboqYDZx0-AnPNDsGq2A3cn\"\n",
        "output = \"unofficial.json\"\n",
        "gdown.download(id=id, output=output)                  # Latest dataset update: 19 Dec 2019\n",
        "\n",
        "id = \"1TzxsRbWdp3y8Mr6oiRQqynDo_MqkOaQi\"\n",
        "output = \"official.json\"\n",
        "gdown.download(id=id, output=output)                  # Latest dataset update: 13 Feb 2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MK_apT3sqzi"
      },
      "outputs": [],
      "source": [
        "def download_image(image):\n",
        "    file_name = image['file_name'].split('/')[1].split('.jpg')[0]\n",
        "    image_url = image['flickr_640_url']\n",
        "    file_path = image['file_path']\n",
        "\n",
        "    if not os.path.isfile(file_path):\n",
        "      if image_url is None:\n",
        "        image_url = image['flickr_url']\n",
        "      response = requests.get(image_url)\n",
        "      img = Image.open(BytesIO(response.content))\n",
        "      if img.size != (480,640):\n",
        "        img = img.resize((480,640))\n",
        "      if img.mode == 'RGBA':\n",
        "          img = img.convert('RGB')\n",
        "      try:\n",
        "          img.save(file_path, exif=img.info[\"exif\"])\n",
        "      except:\n",
        "          img.save(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "We_v9aATx3J6"
      },
      "outputs": [],
      "source": [
        "def resize_bbox(bbox, original_size, new_size):\n",
        "    original_width, original_height = original_size\n",
        "    x, y, width, height = bbox\n",
        "\n",
        "    width_scale = new_size[0] / original_width\n",
        "    height_scale = new_size[1] / original_height\n",
        "\n",
        "    new_x = x * width_scale\n",
        "    new_y = y * height_scale\n",
        "    new_width = width * width_scale\n",
        "    new_height = height * height_scale\n",
        "\n",
        "    return [new_x, new_y, new_width, new_height]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "resize_bbox([66.0, 112.333336, 1045.0, 770.000064], (3024,4032), (480,640))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVhayc4Jm79l"
      },
      "outputs": [],
      "source": [
        "unoff_dir = \"/data/unofficial\"\n",
        "if os.path.exists(unoff_dir):\n",
        "  shutil.rmtree(unoff_dir, ignore_errors=True)\n",
        "os.makedirs(unoff_dir)\n",
        "os.makedirs(os.path.join(unoff_dir, \"images\"))\n",
        "os.makedirs(os.path.join(unoff_dir, \"labels\"))\n",
        "\n",
        "unoff_json = \"unofficial.json\"\n",
        "\n",
        "with open(unoff_json ,\"r\") as f:\n",
        "  data = json.loads(f.read())\n",
        "  nr_images = len(data['images'])\n",
        "  file_names = {}\n",
        "  image_sizes = {}\n",
        "\n",
        "  for i in range(nr_images):\n",
        "    image = data['images'][i]\n",
        "    file_name = image['file_name'].split('/')[1].split('.')[0]\n",
        "    id = image['id']\n",
        "    file_names[id] = file_name\n",
        "    image_sizes[id] = (image['width'], image['height'])\n",
        "    data['images'][i]['file_path'] = os.path.join(unoff_dir, \"images\", file_name+\".jpg\")\n",
        "\n",
        "\n",
        "  max_workers = 16\n",
        "  with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "    futures = [executor.submit(download_image, image) for image in data['images']]\n",
        "    for future in futures:\n",
        "        future.result()\n",
        "\n",
        "  nr_anno = len(data['annotations'])\n",
        "  labels = [[] for _ in range(nr_images)]\n",
        "  for i in range(nr_anno):\n",
        "    annotation = data['annotations'][i]\n",
        "    category_id = annotation['category_id']\n",
        "    bbox = annotation['bbox']\n",
        "    image_id = annotation['image_id']\n",
        "    label_path = os.path.join(unoff_dir, \"labels\")\n",
        "\n",
        "    new_bbox = resize_bbox(bbox, image_sizes[image_id], (480,640))\n",
        "    labels[image_id].append([category_id, new_bbox[0], new_bbox[1], new_bbox[2], new_bbox[3]])\n",
        "\n",
        "  for image_id, annotation_list in enumerate(labels):\n",
        "    file_path = os.path.join(unoff_dir, \"labels\", f\"{file_names[image_id]}.txt\")\n",
        "    with open(file_path, \"w\") as file:\n",
        "      for annotation in annotation_list:\n",
        "          line = \" \".join(map(str, annotation)) + \"\\n\"\n",
        "          file.write(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "502hwlyAEc_8",
        "outputId": "0481cece-9c2d-436f-a400-bd0954b0aac3"
      },
      "outputs": [],
      "source": [
        "off_dir = \"/data/official\"\n",
        "if os.path.exists(off_dir):\n",
        "  shutil.rmtree(off_dir, ignore_errors=True)\n",
        "os.makedirs(off_dir)\n",
        "os.makedirs(os.path.join(off_dir, \"images\"))\n",
        "os.makedirs(os.path.join(off_dir, \"labels\"))\n",
        "\n",
        "off_json = \"official.json\"\n",
        "\n",
        "with open(off_json ,\"r\") as f:\n",
        "  data = json.loads(f.read())\n",
        "  nr_images = len(data['images'])\n",
        "  file_names = {}\n",
        "  image_sizes = {}\n",
        "\n",
        "  for i in range(nr_images):\n",
        "    image = data['images'][i]\n",
        "    batch_num = image['file_name'].split('/')[0]\n",
        "    file_name = image['file_name'].split('/')[1].split('.')[0]\n",
        "    file_name = batch_num + \"--\" + file_name\n",
        "    id = image['id']\n",
        "    file_names[id] = file_name\n",
        "    image_sizes[id] = (image['width'], image['height'])\n",
        "    data['images'][i]['file_path'] = os.path.join(off_dir, \"images\", file_name+\".jpg\")\n",
        "\n",
        "  max_workers = 16\n",
        "  with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "    futures = [executor.submit(download_image, image) for image in data['images']]\n",
        "    for future in futures:\n",
        "        future.result()\n",
        "\n",
        "  nr_anno = len(data['annotations'])\n",
        "  labels = [[] for _ in range(nr_images)]\n",
        "  for i in range(nr_anno):\n",
        "    annotation = data['annotations'][i]\n",
        "    category_id = annotation['category_id']\n",
        "    bbox = annotation['bbox']\n",
        "    image_id = annotation['image_id']\n",
        "    label_path = os.path.join(off_dir, \"labels\")\n",
        "\n",
        "    new_bbox = resize_bbox(bbox, image_sizes[image_id], (480,640))\n",
        "    labels[image_id].append([category_id, new_bbox[0], new_bbox[1], new_bbox[2], new_bbox[3]])\n",
        "\n",
        "  for image_id, annotation_list in enumerate(labels):\n",
        "    file_path = os.path.join(off_dir, \"labels\", f\"{file_names[image_id]}.txt\")\n",
        "    with open(file_path, \"w\") as file:\n",
        "      for annotation in annotation_list:\n",
        "          line = \" \".join(map(str, annotation)) + \"\\n\"\n",
        "          file.write(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxFMl7BU_K5a"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(\"/drive\"):\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "dataset_folder = \"data\" #@param{type:\"string\"}\n",
        "\n",
        "dest_dir = os.path.join(\"/drive/MyDrive\", dataset_folder)\n",
        "shutil.copytree(\"/data\", dest_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XOFsT3R-kze"
      },
      "source": [
        "## Download from drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "LRYnl0y6Sk_N",
        "outputId": "3655870a-4b17-491e-c4d8-f697f7dc66f2"
      },
      "outputs": [],
      "source": [
        "if os.path.exists(\"/data\"):\n",
        "  shutil.rmtree(\"/data\")\n",
        "\n",
        "if not os.path.exists(\"data.zip\"):\n",
        "  id = \"1qzFvq1D9OX_4QT2q5-fN-Ct-slniUv_J\"\n",
        "  output = \"/content/data.zip\"\n",
        "  gdown.download(id=id, output=output)\n",
        "\n",
        "!unzip -q /content/data.zip -d /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxA2snOQxvUi"
      },
      "source": [
        "# Global variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "40J6o6WcnHB6"
      },
      "outputs": [],
      "source": [
        "UNSPLIT_DATASET_DIR = \"data\"\n",
        "\n",
        "OFFICIAL_IMG = \"official/images\"\n",
        "OFFICIAL_LABEL = \"official/labels\"\n",
        "UNOFFICIAL_IMG = \"unofficial/images\"\n",
        "UNOFFICIAL_LABEL = \"unofficial/labels\"\n",
        "\n",
        "DATASET_DIR = \"TACO\"\n",
        "\n",
        "TRAIN_IMG = \"train/images\"\n",
        "TRAIN_LABEL = \"train/labels\"\n",
        "\n",
        "VAL_IMG = \"valid/images\"\n",
        "VAL_LABEL = \"valid/labels\"\n",
        "\n",
        "TEST_IMG = \"test/images\"\n",
        "TEST_LABEL = \"test/labels\"\n",
        "\n",
        "TRAIN_SPLIT = 0.85\n",
        "VAL_SPLIT = 0.1\n",
        "TEST_SPLIT = 0.05\n",
        "\n",
        "IMG_PATH_DICT = {\"train\": TRAIN_IMG, \"val\": VAL_IMG, \"test\": TEST_IMG}\n",
        "LABEL_PATH_DICT = {\"train\": TRAIN_LABEL, \"val\": VAL_LABEL, \"test\": TEST_LABEL}\n",
        "\n",
        "USE_SUPERCATEGORY = True\n",
        "\n",
        "IMG_SIZE_W = 480\n",
        "IMG_SIZE_H = 640\n",
        "\n",
        "BATCH_SIZE = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 'Aluminium foil', 1: 'Battery', 2: 'Blister pack', 3: 'Blister pack', 4: 'Bottle', 5: 'Bottle', 6: 'Bottle', 7: 'Bottle cap', 8: 'Bottle cap', 9: 'Broken glass', 10: 'Can', 11: 'Can', 12: 'Can', 13: 'Carton', 14: 'Carton', 15: 'Carton', 16: 'Carton', 17: 'Carton', 18: 'Carton', 19: 'Carton', 20: 'Cup', 21: 'Cup', 22: 'Cup', 23: 'Cup', 24: 'Cup', 25: 'Food waste', 26: 'Glass jar', 27: 'Lid', 28: 'Lid', 29: 'Other plastic', 30: 'Paper', 31: 'Paper', 32: 'Paper', 33: 'Paper', 34: 'Paper bag', 35: 'Paper bag', 36: 'Plastic bag & wrapper', 37: 'Plastic bag & wrapper', 38: 'Plastic bag & wrapper', 39: 'Plastic bag & wrapper', 40: 'Plastic bag & wrapper', 41: 'Plastic bag & wrapper', 42: 'Plastic bag & wrapper', 43: 'Plastic container', 44: 'Plastic container', 45: 'Plastic container', 46: 'Plastic container', 47: 'Plastic container', 48: 'Plastic glooves', 49: 'Plastic utensils', 50: 'Pop tab', 51: 'Rope & strings', 52: 'Scrap metal', 53: 'Shoe', 54: 'Squeezable tube', 55: 'Straw', 56: 'Straw', 57: 'Styrofoam piece', 58: 'Unlabeled litter', 59: 'Cigarette'}\n",
            "60\n",
            "{0: 'Aluminium foil', 1: 'Battery', 2: 'Blister pack', 3: 'Bottle', 4: 'Bottle cap', 5: 'Broken glass', 6: 'Can', 7: 'Carton', 8: 'Cup', 9: 'Food waste', 10: 'Glass jar', 11: 'Lid', 12: 'Other plastic', 13: 'Paper', 14: 'Paper bag', 15: 'Plastic bag & wrapper', 16: 'Plastic container', 17: 'Plastic glooves', 18: 'Plastic utensils', 19: 'Pop tab', 20: 'Rope & strings', 21: 'Scrap metal', 22: 'Shoe', 23: 'Squeezable tube', 24: 'Straw', 25: 'Styrofoam piece', 26: 'Unlabeled litter', 27: 'Cigarette'}\n",
            "28\n"
          ]
        }
      ],
      "source": [
        "official_json = \"official.json\"\n",
        "\n",
        "with open(official_json ,\"r\") as f:\n",
        "  data = json.loads(f.read())\n",
        "  nr_categories = len(data['categories'])\n",
        "\n",
        "  OLD_CLASS_LABELS = {}\n",
        "  CLASS_LABELS = {}\n",
        "\n",
        "  for i in range(nr_categories):\n",
        "    category = data['categories'][i]\n",
        "    if USE_SUPERCATEGORY:\n",
        "      category_name = category['supercategory']\n",
        "    else:\n",
        "      category_name = category['name']\n",
        "    category_id = category['id']\n",
        "    OLD_CLASS_LABELS[category_id] = category_name\n",
        "    if category_name not in CLASS_LABELS.values():\n",
        "      CLASS_LABELS[len(CLASS_LABELS)] = category_name\n",
        "\n",
        "print(OLD_CLASS_LABELS)\n",
        "print(len(OLD_CLASS_LABELS))\n",
        "print(CLASS_LABELS)\n",
        "print(len(CLASS_LABELS))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Relabel all annotations (do this if supercategories are used)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if USE_SUPERCATEGORY:\n",
        "    if os.path.exists(os.path.join(UNSPLIT_DATASET_DIR, \"official/new-labels\")):\n",
        "        shutil.rmtree(os.path.join(UNSPLIT_DATASET_DIR, \"official/new-labels\"))\n",
        "    os.makedirs(os.path.join(UNSPLIT_DATASET_DIR, \"official/new-labels\"))\n",
        "\n",
        "    if os.path.exists(os.path.join(UNSPLIT_DATASET_DIR, \"unofficial/new-labels\")):\n",
        "        shutil.rmtree(os.path.join(UNSPLIT_DATASET_DIR, \"unofficial/new-labels\"))\n",
        "    os.makedirs(os.path.join(UNSPLIT_DATASET_DIR, \"unofficial/new-labels\"))\n",
        "\n",
        "    for file_name in os.listdir(os.path.join(UNSPLIT_DATASET_DIR, OFFICIAL_LABEL)):\n",
        "        file_path = os.path.join(UNSPLIT_DATASET_DIR, OFFICIAL_LABEL, file_name)\n",
        "        \n",
        "        annotations = []\n",
        "        new_annotations = []\n",
        "\n",
        "        with open(file_path, \"r\") as f:\n",
        "            for line in f:\n",
        "                annotations.append(line)\n",
        "        \n",
        "        for i in range(len(annotations)):\n",
        "            try:\n",
        "                annot = annotations[i]\n",
        "                class_id, bbox_x, bbox_y, bbox_h, bbox_w = annot.split(' ')\n",
        "                class_name = OLD_CLASS_LABELS[int(class_id)]\n",
        "                for key, value in CLASS_LABELS.items():\n",
        "                    if value == class_name:\n",
        "                        new_class_id = key\n",
        "                        break\n",
        "                new_annotations.append([new_class_id, bbox_x, bbox_y, bbox_h, bbox_w])\n",
        "            except:\n",
        "                continue\n",
        "        \n",
        "        new_label_path = os.path.join(UNSPLIT_DATASET_DIR, \"official/new-labels\", file_name)\n",
        "        with open(new_label_path, \"w\") as f:\n",
        "            for i in range(len(new_annotations)):\n",
        "                line = \" \".join(map(str, new_annotations[i]))\n",
        "                f.write(line)\n",
        "\n",
        "    for file_name in os.listdir(os.path.join(UNSPLIT_DATASET_DIR, UNOFFICIAL_LABEL)):\n",
        "        file_path = os.path.join(UNSPLIT_DATASET_DIR, UNOFFICIAL_LABEL, file_name)\n",
        "        \n",
        "        annotations = []\n",
        "        new_annotations = []\n",
        "\n",
        "        with open(file_path, \"r\") as f:\n",
        "            for line in f:\n",
        "                annotations.append(line)\n",
        "\n",
        "        for i in range(len(annotations)):\n",
        "            try:\n",
        "                annot = annotations[i]\n",
        "                class_id, bbox_x, bbox_y, bbox_h, bbox_w = annot.split(' ')\n",
        "                class_name = OLD_CLASS_LABELS[int(class_id)]\n",
        "                for key, value in CLASS_LABELS.items():\n",
        "                    if value == class_name:\n",
        "                        new_class_id = key\n",
        "                        break\n",
        "                new_annotations.append([new_class_id, bbox_x, bbox_y, bbox_h, bbox_w])\n",
        "            except:\n",
        "                continue\n",
        "        \n",
        "        new_label_path = os.path.join(UNSPLIT_DATASET_DIR, \"unofficial/new-labels\", file_name)\n",
        "        with open(new_label_path, \"w\") as f:\n",
        "            for i in range(len(new_annotations)):\n",
        "                line = \" \".join(map(str, new_annotations[i]))\n",
        "                f.write(line)\n",
        "\n",
        "    OFFICIAL_LABEL = \"official/new-labels\"\n",
        "    UNOFFICIAL_LABEL = \"unofficial/new-labels\"\n",
        "\n",
        "            "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sn3jDtWKGRA"
      },
      "source": [
        "# Split train-val-test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0TZA1OTKKbj",
        "outputId": "86a80bb6-1bea-44f0-b144-9fa236e7fca7"
      },
      "outputs": [],
      "source": [
        "off_count = len(os.listdir(os.path.join(UNSPLIT_DATASET_DIR, OFFICIAL_IMG)))\n",
        "unoff_count = len(os.listdir(os.path.join(UNSPLIT_DATASET_DIR, UNOFFICIAL_IMG)))\n",
        "total_dataset_count = off_count + unoff_count\n",
        "\n",
        "print(\"Number of official dataset:\", off_count)\n",
        "print(\"Number of unofficial dataset:\", unoff_count)\n",
        "print(\"Total number of dataset:\", total_dataset_count)\n",
        "\n",
        "official_train_count = int(total_dataset_count*TRAIN_SPLIT - unoff_count)\n",
        "official_val_count = int(total_dataset_count*VAL_SPLIT)\n",
        "official_test_count = off_count - official_train_count - official_val_count\n",
        "\n",
        "print(\"\")\n",
        "print(\"Number of total data for training:\", official_train_count + unoff_count)\n",
        "print(\"Number of official data for training:\", official_train_count)\n",
        "print(\"Number of official data for validation:\", official_val_count)\n",
        "print(\"Number of official data for testing:\", official_test_count)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "6FAaXxBwL5HX",
        "outputId": "f4d94231-918a-40fa-ddc6-0622f6788763"
      },
      "outputs": [],
      "source": [
        "if os.path.exists(DATASET_DIR):\n",
        "  shutil.rmtree(DATASET_DIR, ignore_errors=True)\n",
        "\n",
        "os.makedirs(os.path.join(DATASET_DIR, TRAIN_IMG))\n",
        "os.makedirs(os.path.join(DATASET_DIR, TRAIN_LABEL))\n",
        "os.makedirs(os.path.join(DATASET_DIR, VAL_IMG))\n",
        "os.makedirs(os.path.join(DATASET_DIR, VAL_LABEL))\n",
        "os.makedirs(os.path.join(DATASET_DIR, TEST_IMG))\n",
        "os.makedirs(os.path.join(DATASET_DIR, TEST_LABEL))\n",
        "\n",
        "print(\"Directory created\")\n",
        "\n",
        "for file_name in os.listdir(os.path.join(UNSPLIT_DATASET_DIR, UNOFFICIAL_IMG)):\n",
        "  orig_path = os.path.join(UNSPLIT_DATASET_DIR, UNOFFICIAL_IMG, file_name)\n",
        "  dest_path = os.path.join(DATASET_DIR, TRAIN_IMG, file_name)\n",
        "  shutil.copy(orig_path, dest_path)\n",
        "\n",
        "print(\"Unofficial images moved\")\n",
        "\n",
        "for file_name in os.listdir(os.path.join(UNSPLIT_DATASET_DIR, UNOFFICIAL_LABEL)):\n",
        "  orig_path = os.path.join(UNSPLIT_DATASET_DIR, UNOFFICIAL_LABEL, file_name)\n",
        "  dest_path = os.path.join(DATASET_DIR, TRAIN_LABEL, file_name)\n",
        "  shutil.copy(orig_path, dest_path)\n",
        "\n",
        "print(\"Unofficial labels moved\")\n",
        "\n",
        "official_files = os.listdir(os.path.join(UNSPLIT_DATASET_DIR, OFFICIAL_IMG))\n",
        "random.shuffle(official_files)\n",
        "\n",
        "train_dataset = official_files[:official_train_count]\n",
        "val_dataset = official_files[official_train_count:official_train_count+official_val_count]\n",
        "test_dataset = official_files[official_train_count+official_val_count:]\n",
        "\n",
        "for file in train_dataset:\n",
        "  file_name = file.split(\".\")[0]\n",
        "\n",
        "  orig_img_path = os.path.join(UNSPLIT_DATASET_DIR, OFFICIAL_IMG, file)\n",
        "  dest_img_path = os.path.join(DATASET_DIR, TRAIN_IMG, file)\n",
        "  shutil.copy(orig_img_path, dest_img_path)\n",
        "\n",
        "  orig_label_path = os.path.join(UNSPLIT_DATASET_DIR, OFFICIAL_LABEL, file_name+\".txt\")\n",
        "  dest_label_path = os.path.join(DATASET_DIR, TRAIN_LABEL, file_name+\".txt\")\n",
        "  shutil.copy(orig_label_path, dest_label_path)\n",
        "\n",
        "print(\"Official train moved\")\n",
        "\n",
        "for file in val_dataset:\n",
        "  file_name = file.split(\".\")[0]\n",
        "\n",
        "  orig_img_path = os.path.join(UNSPLIT_DATASET_DIR, OFFICIAL_IMG, file)\n",
        "  dest_img_path = os.path.join(DATASET_DIR, VAL_IMG, file)\n",
        "  shutil.copy(orig_img_path, dest_img_path)\n",
        "\n",
        "  orig_label_path = os.path.join(UNSPLIT_DATASET_DIR, OFFICIAL_LABEL, file_name+\".txt\")\n",
        "  dest_label_path = os.path.join(DATASET_DIR, VAL_LABEL, file_name+\".txt\")\n",
        "  shutil.copy(orig_label_path, dest_label_path)\n",
        "\n",
        "print(\"Official validation moved\")\n",
        "\n",
        "for file in test_dataset:\n",
        "  file_name = file.split(\".\")[0]\n",
        "\n",
        "  orig_img_path = os.path.join(UNSPLIT_DATASET_DIR, OFFICIAL_IMG, file)\n",
        "  dest_img_path = os.path.join(DATASET_DIR, TEST_IMG, file)\n",
        "  shutil.copy(orig_img_path, dest_img_path)\n",
        "\n",
        "  orig_label_path = os.path.join(UNSPLIT_DATASET_DIR, OFFICIAL_LABEL, file_name+\".txt\")\n",
        "  dest_label_path = os.path.join(DATASET_DIR, TEST_LABEL, file_name+\".txt\")\n",
        "  shutil.copy(orig_label_path, dest_label_path)\n",
        "\n",
        "print(\"Official test moved\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Number of total training data:\", len(os.listdir(os.path.join(DATASET_DIR, TRAIN_IMG))))\n",
        "print(\"Number of total validation data:\", len(os.listdir(os.path.join(DATASET_DIR, VAL_IMG))))\n",
        "print(\"Number of total testing data:\", len(os.listdir(os.path.join(DATASET_DIR, TEST_IMG))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aOf7eIv2k-D"
      },
      "source": [
        "# Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_label(line):\n",
        "    class_id, box_x, box_y, box_w, box_h = line.strip().split()\n",
        "    return int(class_id), float(box_x), float(box_y), float(box_w), float(box_h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJvVsxpLVHkB"
      },
      "outputs": [],
      "source": [
        "def get_file_count_per_data_type(dataset_type):\n",
        "  label_dir = os.path.join(DATASET_DIR, LABEL_PATH_DICT[dataset_type])\n",
        "  label_files = [f for f in os.listdir(label_dir)]\n",
        "\n",
        "  img_dir = os.path.join(DATASET_DIR, IMG_PATH_DICT[dataset_type])\n",
        "  img_files = [f for f in os.listdir(img_dir)]\n",
        "\n",
        "  print(f\"There are {len(label_files)} files in {dataset_type} set\")\n",
        "  if (len(label_files) != len(img_files)):\n",
        "    print(f\"Warning: There are {len(label_files)} labels but also {len(img_files)} images in {dataset_type} set\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6uTSpmLyYp3"
      },
      "outputs": [],
      "source": [
        "def get_datacount_per_class(dataset_type, class_list):\n",
        "  label_dir = os.path.join(DATASET_DIR, LABEL_PATH_DICT[dataset_type])\n",
        "  label_files = [f for f in os.listdir(label_dir)]\n",
        "  class_counts = [0] * len(class_list)\n",
        "\n",
        "  for file_name in label_files:\n",
        "    file_path = os.path.join(label_dir, file_name)\n",
        "    with open(file_path, \"r\") as f:\n",
        "      for line in f:\n",
        "        class_id, _, _, _, _ = read_label(line)\n",
        "        class_counts[class_id] += 1\n",
        "  \n",
        "  class_names = []\n",
        "  for _, value in class_list.items():\n",
        "    class_names.append(value)\n",
        "\n",
        "  sorted_counts_names = sorted(zip(class_counts, class_names), reverse=True)\n",
        "  sorted_counts, sorted_names = zip(*sorted_counts_names)\n",
        "\n",
        "  return sorted_counts, sorted_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "215Igqi03J8V"
      },
      "outputs": [],
      "source": [
        "def plot_datacount_per_class(class_list):\n",
        "    plt.figure(figsize=(21, 21))\n",
        "\n",
        "    plt.subplot(3, 1, 1)\n",
        "    count, names = get_datacount_per_class(\"train\", class_list)\n",
        "    plt.title(\"Train\")\n",
        "    plt.barh(names, count)\n",
        "\n",
        "    plt.subplot(3, 1, 2)\n",
        "    count, names = get_datacount_per_class(\"val\", class_list)\n",
        "    plt.title(\"Validation\")\n",
        "    plt.barh(names, count)\n",
        "\n",
        "    plt.subplot(3, 1, 3)\n",
        "    count, names = get_datacount_per_class(\"test\", class_list)\n",
        "    plt.title(\"Test\")\n",
        "    plt.barh(names, count)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_datacount_per_class(CLASS_LABELS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_WArvlS9fsD"
      },
      "outputs": [],
      "source": [
        "def display_images(image_list, num_images, plot_title, dataset_type):\n",
        "  label_dir = os.path.join(DATASET_DIR, LABEL_PATH_DICT[dataset_type])\n",
        "  img_dir = os.path.join(DATASET_DIR, IMG_PATH_DICT[dataset_type])\n",
        "  plt.figure(figsize=(12, 12))\n",
        "  for i, label_name in enumerate(image_list):\n",
        "    image_name = label_name.replace(\".txt\", \".jpg\")\n",
        "    img_path = os.path.join(img_dir, image_name)\n",
        "    label_path = os.path.join(label_dir, label_name)\n",
        "\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    h, w, _ = img.shape\n",
        "\n",
        "    ax = plt.subplot(num_images, num_images, i + 1)\n",
        "    plt.imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    with open(label_path, \"r\") as f:\n",
        "      for line in f:\n",
        "        _, x1, y1, box_width, box_height = read_label(line)\n",
        "\n",
        "        rect = patches.Rectangle(\n",
        "            (x1, y1),\n",
        "            box_width,\n",
        "            box_height,\n",
        "            linewidth=1,\n",
        "            edgecolor=\"r\",\n",
        "            facecolor=\"none\",\n",
        "        )\n",
        "        ax.add_patch(rect)\n",
        "      if (i+1 == len(image_list)):\n",
        "        break\n",
        "  plt.tight_layout()\n",
        "  plt.suptitle(\n",
        "      plot_title,\n",
        "      fontsize=30,\n",
        "      y=1.05,\n",
        "      fontweight=\"bold\",\n",
        "  )\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqeIVz-h7cwr"
      },
      "outputs": [],
      "source": [
        "def display_images_of_certain_class(class_name, dataset_type, num_images, class_list):\n",
        "  if class_name not in class_list.values():\n",
        "    raise ValueError(\"Class name not found in the class list.\")\n",
        "\n",
        "  label_dir = os.path.join(DATASET_DIR, LABEL_PATH_DICT[dataset_type])\n",
        "  label_files = [f for f in os.listdir(label_dir)]\n",
        "  for key, value in class_list.items():\n",
        "    if value == class_name:\n",
        "      index = key\n",
        "      break\n",
        "  image_list = []\n",
        "\n",
        "  for file_name in label_files:\n",
        "    file_path = os.path.join(label_dir, file_name)\n",
        "    with open(file_path, \"r\") as f:\n",
        "      for line in f:\n",
        "        class_id, _, _, _, _ = read_label(line)\n",
        "        class_id = int(class_id)\n",
        "        if class_id == index:\n",
        "          image_list.append(file_name)\n",
        "          break\n",
        "  if len(image_list) > num_images * num_images:\n",
        "    selected_images = random.sample(image_list, num_images * num_images)\n",
        "  else:\n",
        "    selected_images = image_list\n",
        "  plot_title = f\"Displaying images containing class: {class_name}\"\n",
        "  display_images(selected_images, num_images, plot_title, dataset_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "display_images_of_certain_class(\"Bottle\", \"train\", 3, CLASS_LABELS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0MuJLiuBgEp"
      },
      "outputs": [],
      "source": [
        "def get_box_count_per_image(dataset_type, box_count_treshold=30):\n",
        "  label_dir = os.path.join(DATASET_DIR, LABEL_PATH_DICT[dataset_type])\n",
        "  label_files = [f for f in os.listdir(label_dir)]\n",
        "\n",
        "  average_box_count = 0\n",
        "  max_box_count = 0\n",
        "  high_box_count_images = []\n",
        "\n",
        "  for file_name in label_files:\n",
        "    file_path = os.path.join(label_dir, file_name)\n",
        "    with open(file_path, \"r\") as f:\n",
        "      boxes = f.readlines()\n",
        "      average_box_count += len(boxes)\n",
        "      max_box_count = max(max_box_count, len(boxes))\n",
        "      if (len(boxes)) > box_count_treshold:\n",
        "        high_box_count_images.append(file_name)\n",
        "\n",
        "  average_box_count /= len(label_files)\n",
        "\n",
        "  return average_box_count, max_box_count, high_box_count_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsBm6vo-In1I"
      },
      "outputs": [],
      "source": [
        "def get_box_size_per_image(dataset_type, box_size_treshold=0.00015):\n",
        "  label_dir = os.path.join(DATASET_DIR, LABEL_PATH_DICT[dataset_type])\n",
        "  label_files = [f for f in os.listdir(label_dir)]\n",
        "\n",
        "  avg_box_size = 0\n",
        "  small_box_size_images = []\n",
        "\n",
        "  for file_name in label_files:\n",
        "    file_path = os.path.join(label_dir, file_name)\n",
        "    #print(file_path)\n",
        "    with open(file_path, \"r\") as f:\n",
        "      for line in f:\n",
        "        #print(line)\n",
        "        _, _, _, width, height = read_label(line)\n",
        "        box_size = (width * height) / (IMG_SIZE_W * IMG_SIZE_H)\n",
        "        avg_box_size += box_size\n",
        "        #print(width, height, avg_box_size, box_size)\n",
        "        if box_size < box_size_treshold:\n",
        "          small_box_size_images.append(file_name)\n",
        "\n",
        "  avg_box_size /= len(label_files)\n",
        "  return avg_box_size, small_box_size_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGv6rob9OIKG"
      },
      "outputs": [],
      "source": [
        "def get_filtered_boxes_overlap(boxes, iou_treshold=0.35):\n",
        "  if (len(boxes) == 1):\n",
        "    return boxes\n",
        "\n",
        "  removed_boxes = []\n",
        "\n",
        "  for i in range(len(boxes)-1):\n",
        "    for j in range(i+1, len(boxes)):\n",
        "      class1, x1, y1, w1, h1 = read_label(boxes[i])\n",
        "      class2, x2, y2, w2, h2 = read_label(boxes[j])\n",
        "\n",
        "      if class1 != class2:\n",
        "        continue\n",
        "\n",
        "      x_overlap = max(0, min(x1 + w1 / 2, x2 + w2 / 2) - max(x1 - w1 / 2, x2 - w2 / 2))\n",
        "      y_overlap = max(0, min(y1 + h1 / 2, y2 + h2 / 2) - max(y1 - h1 / 2, y2 - h2 / 2))\n",
        "\n",
        "      intersect = x_overlap * y_overlap\n",
        "      union = w1 * h1 + w2 * h2 - intersect\n",
        "      IoU = intersect / union\n",
        "\n",
        "      if IoU > iou_treshold:\n",
        "        if w1*h1 < w2*h2:\n",
        "          removed_boxes.append(i)\n",
        "        else:\n",
        "          removed_boxes.append(j)\n",
        "\n",
        "  filtered_boxes = [box for i, box in enumerate(boxes) if i not in removed_boxes]\n",
        "\n",
        "  return filtered_boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5VHoK0GLWy2"
      },
      "outputs": [],
      "source": [
        "def get_number_of_overlapping_boxes(dataset_type, iou_treshold=0.35):\n",
        "  label_dir = os.path.join(DATASET_DIR, LABEL_PATH_DICT[dataset_type])\n",
        "  label_files = [f for f in os.listdir(label_dir)]\n",
        "\n",
        "  total_box_count = 0\n",
        "  total_high_overlap_box_count = 0\n",
        "  high_box_overlap_images = []\n",
        "\n",
        "  for file_name in label_files:\n",
        "    file_path = os.path.join(label_dir, file_name)\n",
        "\n",
        "    boxes = []\n",
        "    with open(file_path, \"r\") as f:\n",
        "      for line in f:\n",
        "        boxes.append(line)\n",
        "\n",
        "    filtered_boxes = get_filtered_boxes_overlap(boxes, iou_treshold)\n",
        "\n",
        "    total_box_count += len(boxes)\n",
        "    total_high_overlap_box_count += len(boxes) - len(filtered_boxes)\n",
        "    if (len(boxes) != len(filtered_boxes)):\n",
        "      high_box_overlap_images.append(file_name)\n",
        "  return total_box_count, total_high_overlap_box_count, high_box_overlap_images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n69tnCaI3JbF"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Invalid box boundaries (infinite)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def invalid_box_boundary(dataset_type):\n",
        "    dir_path = os.path.join(DATASET_DIR, LABEL_PATH_DICT[dataset_type])\n",
        "    invalid_boxes = 0\n",
        "    for file_name in os.listdir(dir_path):\n",
        "        file_path = os.path.join(dir_path, file_name)\n",
        "        \n",
        "        new_annotations = []\n",
        "\n",
        "        with open(file_path, \"r\") as f:\n",
        "            for line in f:\n",
        "                class_id, bbox_x, bbox_y, bbox_h, bbox_w = line.split(' ')\n",
        "                if (bbox_x == \"inf\" or bbox_x == \"-inf\" or bbox_y == \"inf\" or bbox_y == \"-inf\" or bbox_h == \"inf\" or bbox_h == \"-inf\" or bbox_w == \"inf\" or bbox_w == \"-inf\"):\n",
        "                    invalid_boxes += 1\n",
        "                    continue\n",
        "                new_annotations.append([class_id, bbox_x, bbox_y, bbox_h, bbox_w])\n",
        "        \n",
        "        with open(file_path, \"w\") as f:\n",
        "            for i in range(len(new_annotations)):\n",
        "                line = \" \".join(map(str, new_annotations[i]))\n",
        "                f.write(line)\n",
        "    print(f\"Found and removed {invalid_boxes} invalid boxes in {dataset_type} set\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "invalid_box_boundary(\"train\")\n",
        "invalid_box_boundary(\"val\")\n",
        "invalid_box_boundary(\"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYeBfdqg7Heh"
      },
      "source": [
        "## Too many boxes in 1 image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAbHbVMO7G1h"
      },
      "outputs": [],
      "source": [
        "def images_with_high_box_count(dataset_type, num_images, box_count_treshold=30):\n",
        "  _, _, high_box_count_images = get_box_count_per_image(dataset_type, box_count_treshold = box_count_treshold)\n",
        "\n",
        "  if len(high_box_count_images) > num_images * num_images:\n",
        "    selected_images = random.sample(high_box_count_images, num_images * num_images)\n",
        "  else:\n",
        "    selected_images = high_box_count_images\n",
        "\n",
        "  plot_title = f\"Images with at least {box_count_treshold} boxes in {dataset_type} set\"\n",
        "  display_images(selected_images, num_images, plot_title, dataset_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d0k9mHbgH03e",
        "outputId": "4b4d39e3-4e33-4620-ef89-08d90b3741d5"
      },
      "outputs": [],
      "source": [
        "images_with_high_box_count(\"train\", 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1naR0_sgHxYt"
      },
      "outputs": [],
      "source": [
        "def discard_images_with_high_box_count(dataset_type, box_count_treshold=30):\n",
        "  _, _, high_box_count_images = get_box_count_per_image(dataset_type, box_count_treshold = box_count_treshold)\n",
        "\n",
        "  label_dir = os.path.join(DATASET_DIR, LABEL_PATH_DICT[dataset_type])\n",
        "  img_dir = os.path.join(DATASET_DIR, IMG_PATH_DICT[dataset_type])\n",
        "  count = 0\n",
        "\n",
        "  for label_name in high_box_count_images:\n",
        "    img_name = label_name.replace(\".txt\", \".jpg\")\n",
        "\n",
        "    img_path = os.path.join(img_dir, img_name)\n",
        "    label_path = os.path.join(label_dir, label_name)\n",
        "\n",
        "    if os.path.exists(img_path):\n",
        "      os.remove(img_path)\n",
        "    if os.path.exists(label_path):\n",
        "      os.remove(label_path)\n",
        "\n",
        "    count += 1\n",
        "  print(f\"Removed {count} images from {dataset_type} set\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTH0D1WxH35X",
        "outputId": "4e3b10e7-0cb3-4dfd-9ab5-fe53a2653377"
      },
      "outputs": [],
      "source": [
        "discard_images_with_high_box_count(\"train\")\n",
        "discard_images_with_high_box_count(\"val\")\n",
        "discard_images_with_high_box_count(\"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AUfAZUyISdV"
      },
      "source": [
        "## Box size too small"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8qJDlWOIVjH"
      },
      "outputs": [],
      "source": [
        "def images_with_small_boxes(dataset_type, num_images, box_size_treshold=0.00015):\n",
        "  _, small_box_size_images = get_box_size_per_image(dataset_type, box_size_treshold = box_size_treshold)\n",
        "\n",
        "  if len(small_box_size_images) > num_images * num_images:\n",
        "    selected_images = random.sample(small_box_size_images, num_images * num_images)\n",
        "  else:\n",
        "    selected_images = small_box_size_images\n",
        "\n",
        "  plot_title = f\"Images with box sizes below {box_size_treshold} boxes in {dataset_type} set\"\n",
        "  display_images(selected_images, num_images, plot_title, dataset_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 919
        },
        "id": "qIC9IsktKHjw",
        "outputId": "64f03878-621d-4b34-bd08-c7ae145820e9"
      },
      "outputs": [],
      "source": [
        "images_with_small_boxes(\"train\", 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbattJpKJ7ZL"
      },
      "outputs": [],
      "source": [
        "def discard_images_with_small_boxes(dataset_type, box_size_treshold=0.00015):\n",
        "  _, small_box_size_images = get_box_size_per_image(dataset_type, box_size_treshold = box_size_treshold)\n",
        "\n",
        "  label_dir = os.path.join(DATASET_DIR, LABEL_PATH_DICT[dataset_type])\n",
        "  img_dir = os.path.join(DATASET_DIR, IMG_PATH_DICT[dataset_type])\n",
        "  count = 0\n",
        "\n",
        "  for label_name in small_box_size_images:\n",
        "    img_name = label_name.replace(\".txt\", \".jpg\")\n",
        "\n",
        "    img_path = os.path.join(img_dir, img_name)\n",
        "    label_path = os.path.join(label_dir, label_name)\n",
        "\n",
        "    if os.path.exists(img_path):\n",
        "      os.remove(img_path)\n",
        "    if os.path.exists(label_path):\n",
        "      os.remove(label_path)\n",
        "\n",
        "    count += 1\n",
        "  print(f\"Removed {count} images from {dataset_type} set\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfOe9caZKJC3",
        "outputId": "3364b4ba-fddf-43d1-c12b-47981cc8cb09"
      },
      "outputs": [],
      "source": [
        "discard_images_with_small_boxes(\"train\")\n",
        "discard_images_with_small_boxes(\"val\")\n",
        "discard_images_with_small_boxes(\"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kP2XzOm6O9Rg"
      },
      "source": [
        "## Big overlap between boxes of same class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKfRNPZOPBbZ"
      },
      "outputs": [],
      "source": [
        "def images_with_high_box_overlap(dataset_type, num_images, iou_treshold=0.35):\n",
        "  _, _, high_box_overlap_images = get_number_of_overlapping_boxes(dataset_type, iou_treshold = iou_treshold)\n",
        "\n",
        "  if len(high_box_overlap_images) > num_images * num_images:\n",
        "    selected_images = random.sample(high_box_overlap_images, num_images * num_images)\n",
        "  else:\n",
        "    selected_images = high_box_overlap_images\n",
        "\n",
        "  plot_title = f\"Images with box overlap above {iou_treshold} boxes in {dataset_type} set\"\n",
        "  display_images(selected_images, num_images, plot_title, dataset_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "id": "4dHW3rJvPy8R",
        "outputId": "62cc4a32-5e22-4473-b205-b4ad9ea805d3"
      },
      "outputs": [],
      "source": [
        "images_with_high_box_overlap(\"train\", 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLI2yi2jPZod"
      },
      "outputs": [],
      "source": [
        "def discard_images_with_high_box_overlap(dataset_type, iou_treshold=0.35):\n",
        "  _, _, high_box_overlap_images = get_number_of_overlapping_boxes(dataset_type, iou_treshold = iou_treshold)\n",
        "\n",
        "  label_dir = os.path.join(DATASET_DIR, LABEL_PATH_DICT[dataset_type])\n",
        "  img_dir = os.path.join(DATASET_DIR, IMG_PATH_DICT[dataset_type])\n",
        "  count = 0\n",
        "\n",
        "  for label_name in high_box_overlap_images:\n",
        "    img_name = label_name.replace(\".txt\", \".jpg\")\n",
        "\n",
        "    img_path = os.path.join(img_dir, img_name)\n",
        "    label_path = os.path.join(label_dir, label_name)\n",
        "\n",
        "    if os.path.exists(img_path):\n",
        "      os.remove(img_path)\n",
        "    if os.path.exists(label_path):\n",
        "      os.remove(label_path)\n",
        "\n",
        "    count += 1\n",
        "  print(f\"Removed {count} images from {dataset_type} set\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbS_aqN3PvtX",
        "outputId": "e00acd11-cea9-4029-8526-9c3ecb62ba37"
      },
      "outputs": [],
      "source": [
        "discard_images_with_high_box_overlap(\"train\")\n",
        "discard_images_with_high_box_overlap(\"val\")\n",
        "discard_images_with_high_box_overlap(\"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dra6G3xw7Fr7"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kamkbyYCe6B7"
      },
      "source": [
        "## Dataset Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGnJrxOsV0aa",
        "outputId": "bd1d77c5-5304-4034-ef3e-baed378dae7f"
      },
      "outputs": [],
      "source": [
        "get_file_count_per_data_type(\"train\")\n",
        "get_file_count_per_data_type(\"val\")\n",
        "get_file_count_per_data_type(\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgM39xlBWemT",
        "outputId": "fe58dc7d-38af-4150-fe02-bceb26807d3c"
      },
      "outputs": [],
      "source": [
        "print(len(CLASS_LABELS))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iv8zPDEQXLfh",
        "outputId": "3a9610a1-2032-45e9-91e3-5c34aef25890"
      },
      "outputs": [],
      "source": [
        "def get_image_resolution(image_path):\n",
        "    with Image.open(image_path) as img:\n",
        "        width, height = img.size\n",
        "    return width, height\n",
        "\n",
        "files = os.listdir(os.path.join(DATASET_DIR, TRAIN_IMG))\n",
        "file_name = files[0]\n",
        "file_path = os.path.join(DATASET_DIR, TRAIN_IMG, file_name)\n",
        "width, height = get_image_resolution(file_path)\n",
        "print(f\"Image resolution: {width}x{height}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKERNkpNeyVc"
      },
      "source": [
        "## YOLO V8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdHzURvee21x"
      },
      "source": [
        "### Download YOLO V8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bVf3BFY6XiKV",
        "outputId": "90dac8cf-f648-4658-8906-fc60f406ec4f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'yolov8x.pt'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "url = \"https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x.pt\"\n",
        "save_path = \"yolov8x.pt\"\n",
        "wget.download(url, save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### View architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YOLO(\n",
            "  (model): DetectionModel(\n",
            "    (model): Sequential(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(3, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(80, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (2): C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(400, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0-2): 3 x Bottleneck(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (3): Conv(\n",
            "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (4): C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0-5): 6 x Bottleneck(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (5): Conv(\n",
            "        (conv): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (6): C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(2560, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0-5): 6 x Bottleneck(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (7): Conv(\n",
            "        (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (8): C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0-2): 3 x Bottleneck(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (9): SPPF(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
            "      )\n",
            "      (10): Upsample(scale_factor=2.0, mode='nearest')\n",
            "      (11): Concat()\n",
            "      (12): C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0-2): 3 x Bottleneck(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (13): Upsample(scale_factor=2.0, mode='nearest')\n",
            "      (14): Concat()\n",
            "      (15): C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(800, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0-2): 3 x Bottleneck(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (16): Conv(\n",
            "        (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (17): Concat()\n",
            "      (18): C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0-2): 3 x Bottleneck(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (19): Conv(\n",
            "        (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (20): Concat()\n",
            "      (21): C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0-2): 3 x Bottleneck(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (22): Detect(\n",
            "        (cv2): ModuleList(\n",
            "          (0): Sequential(\n",
            "            (0): Conv(\n",
            "              (conv): Conv2d(320, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv(\n",
            "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): Conv2d(80, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (1-2): 2 x Sequential(\n",
            "            (0): Conv(\n",
            "              (conv): Conv2d(640, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv(\n",
            "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): Conv2d(80, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (cv3): ModuleList(\n",
            "          (0): Sequential(\n",
            "            (0): Conv(\n",
            "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv(\n",
            "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (1-2): 2 x Sequential(\n",
            "            (0): Conv(\n",
            "              (conv): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv(\n",
            "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (dfl): DFL(\n",
            "          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = YOLO('YOLOv8x.pt')\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Layer Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Conv(tf.keras.layers.Layer):\n",
        "    def __init__(self, filter_size, kernel_size=3, strides=1, padding='same'):\n",
        "        super(Conv, self).__init__()\n",
        "        self.conv = tf.keras.layers.Conv2D(filter_size, kernel_size=kernel_size, strides=strides, padding=padding)\n",
        "        self.bn = tf.keras.layers.BatchNormalization(epsilon=0.001, momentum=0.03)\n",
        "        self.actv = tf.keras.layers.Activation('swish')\n",
        "        \n",
        "    def call(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.actv(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Bottleneck(tf.keras.layers.Layer):\n",
        "    def __init__(self, filter_size):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.cv1 = Conv(filter_size, 3, 1, 'same')\n",
        "        self.cv2 = Conv(filter_size, 3, 1, 'same')\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.cv1(x)\n",
        "        x = self.cv2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "class C2f(tf.keras.layers.Layer):\n",
        "    def __init__(self, filter_size, num_bottlenecks):\n",
        "        super(C2f, self).__init__()\n",
        "        self.cv1 = Conv(filter_size, 1, 1, 'valid')\n",
        "        self.m = [Bottleneck(filter_size) for _ in range(num_bottlenecks)]\n",
        "        self.cv2 = Conv(filter_size * (num_bottlenecks + 1), 1, 1, 'valid')\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.cv1(x)\n",
        "        x = self.cv2(x)\n",
        "        for layer in self.m:\n",
        "            x = layer(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SPPF(tf.keras.Model):\n",
        "    def __init__(self, filter_size):\n",
        "        super(SPPF, self).__init__()\n",
        "        self.cv1 = Conv(filter_size, 1, 1, 'valid')\n",
        "        self.cv2 = Conv(2 * filter_size, 1, 1, 'valid')\n",
        "        self.m = tf.keras.layers.MaxPool2D(pool_size=5, strides=1, padding='same')\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.cv1(x)\n",
        "        x = self.cv2(x)\n",
        "        x = self.m(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, out_channels, kernel_size=3, strides=1, padding='same'):\n",
        "        super(CustomLayer, self).__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(128, kernel_size=kernel_size, strides=strides, padding=padding)\n",
        "        self.conv2 = tf.keras.layers.Conv2D(out_channels, kernel_size=kernel_size, strides=strides, padding=padding)\n",
        "        self.bn = tf.keras.layers.BatchNormalization(epsilon=0.001, momentum=0.03)\n",
        "        self.relu = tf.keras.layers.ReLU()\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.relu(self.bn(self.conv1(x)))\n",
        "        x = self.relu(self.bn(self.conv2(x)))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Make a new model with the YOLO layers and the new custom layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
              "\n",
              " conv2d_88 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">416</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">416</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">2,240</span> \n",
              "\n",
              " batch_normalization_87           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">416</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">416</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
              "\n",
              " activation_86 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">416</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">416</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " conv2d_88 (\u001b[38;5;33mConv2D\u001b[0m)               (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m416\u001b[0m, \u001b[38;5;34m416\u001b[0m, \u001b[38;5;34m80\u001b[0m)            \u001b[38;5;34m2,240\u001b[0m \n",
              "\n",
              " batch_normalization_87           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m416\u001b[0m, \u001b[38;5;34m416\u001b[0m, \u001b[38;5;34m80\u001b[0m)              \u001b[38;5;34m320\u001b[0m \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
              "\n",
              " activation_86 (\u001b[38;5;33mActivation\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m416\u001b[0m, \u001b[38;5;34m416\u001b[0m, \u001b[38;5;34m80\u001b[0m)                \u001b[38;5;34m0\u001b[0m \n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,560</span> (10.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,560\u001b[0m (10.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,400</span> (9.38 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,400\u001b[0m (9.38 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> (640.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m160\u001b[0m (640.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "test_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(416, 416, 3)),\n",
        "    tf.keras.layers.Conv2D(80, kernel_size=3, strides=1, padding='same'),\n",
        "    tf.keras.layers.BatchNormalization(epsilon=0.001, momentum=0.03),\n",
        "    tf.keras.layers.Activation('swish')\n",
        "])\n",
        "test_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(test_model.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\layer.py:1295: UserWarning: Layer 'custom_layer_6' looks like it has unbuilt state, but Keras is not able to trace the layer `call()` in order to build it automatically. Possible causes:\n",
            "1. The `call()` method of your layer may be crashing. Try to `__call__()` the layer eagerly on some test input first to see if it works. E.g. `x = np.random.random((3, 4)); y = layer(x)`\n",
            "2. If the `call()` method is correct, then you may need to implement the `def build(self, input_shape)` method on your layer. It should create all variables used by the layer (e.g. by calling `layer.build()` on all its children layers).\n",
            "Exception encountered: ''Input 0 of layer \"batch_normalization_603\" is incompatible with the layer: expected axis -1 of input shape to have value 128, but received input with shape (None, 52, 52, 28)''\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Exception encountered when calling CustomLayer.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'custom_layer_6' (of type CustomLayer). Either the `CustomLayer.call()` method is incorrect, or you need to implement the `CustomLayer.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\nInput 0 of layer \"batch_normalization_603\" is incompatible with the layer: expected axis -1 of input shape to have value 128, but received input with shape (None, 52, 52, 28)\u001b[0m\n\nArguments received by CustomLayer.call():\n   args=('<KerasTensor shape=(None, 52, 52, 640), dtype=float32, sparse=False, name=keras_tensor_263>',)\n   kwargs=<class 'inspect._empty'>",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[89], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m new_model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSequential\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m416\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m416\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mConv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m80\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mConv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m160\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC2f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m160\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mConv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m320\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC2f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m320\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mConv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC2f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mConv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC2f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mSPPF\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m320\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUpSampling2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnearest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC2f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUpSampling2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnearest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC2f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m160\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mConv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m320\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC2f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mConv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC2f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mCustomLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mCLASS_LABELS\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m new_model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(new_model\u001b[38;5;241m.\u001b[39msummary())\n",
            "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\models\\sequential.py:74\u001b[0m, in \u001b[0;36mSequential.__init__\u001b[1;34m(self, layers, trainable, name)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m layers:\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd(layer, rebuild\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_rebuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\models\\sequential.py:139\u001b[0m, in \u001b[0;36mSequential._maybe_rebuild\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m], InputLayer) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    138\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mbatch_shape\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\layer.py:223\u001b[0m, in \u001b[0;36mLayer.__new__.<locals>.build_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(original_build_method)\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_open_name_scope():\n\u001b[1;32m--> 223\u001b[0m         \u001b[43moriginal_build_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;66;03m# Record build config.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     signature \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(original_build_method)\n",
            "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\models\\sequential.py:183\u001b[0m, in \u001b[0;36mSequential.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 183\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m         \u001b[38;5;66;03m# Can happen if shape inference is not implemented.\u001b[39;00m\n\u001b[0;32m    186\u001b[0m         \u001b[38;5;66;03m# TODO: consider reverting inbound nodes on layers processed.\u001b[39;00m\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "Cell \u001b[1;32mIn[73], line 11\u001b[0m, in \u001b[0;36mCustomLayer.call\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     10\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)))\n\u001b[1;32m---> 11\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Exception encountered when calling CustomLayer.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'custom_layer_6' (of type CustomLayer). Either the `CustomLayer.call()` method is incorrect, or you need to implement the `CustomLayer.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\nInput 0 of layer \"batch_normalization_603\" is incompatible with the layer: expected axis -1 of input shape to have value 128, but received input with shape (None, 52, 52, 28)\u001b[0m\n\nArguments received by CustomLayer.call():\n   args=('<KerasTensor shape=(None, 52, 52, 640), dtype=float32, sparse=False, name=keras_tensor_263>',)\n   kwargs=<class 'inspect._empty'>"
          ]
        }
      ],
      "source": [
        "new_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(416, 416, 3)),\n",
        "    Conv(80, 3, 1, 'same'),\n",
        "    Conv(160, 3, 1, 'same'),\n",
        "    C2f(160, 3),\n",
        "    Conv(320, 3, 2, 'same'),\n",
        "    C2f(320, 6),\n",
        "    Conv(640, 3, 2, 'same'),\n",
        "    C2f(640, 6),\n",
        "    Conv(640, 3, 2, 'same'),\n",
        "    C2f(640, 3),\n",
        "    SPPF(320),\n",
        "    tf.keras.layers.UpSampling2D(size=2, interpolation='nearest'),\n",
        "    C2f(640, 3),\n",
        "    tf.keras.layers.UpSampling2D(size=2, interpolation='nearest'),\n",
        "    C2f(160, 3),\n",
        "    Conv(320, 3, 2, 'same'),\n",
        "    C2f(640, 3),\n",
        "    Conv(640, 3, 2, 'same'),\n",
        "    C2f(640, 3),\n",
        "    CustomLayer(len(CLASS_LABELS), 3, 1, 'same')\n",
        "])\n",
        "new_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(new_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomLayer(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CustomLayer, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(128)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(128, out_channels, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.relu(self.bn2(self.conv2(x)))\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Custom Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, image_dir, label_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.label_dir = label_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        self.image_files = os.listdir(image_dir)\n",
        "        self.label_files = os.listdir(label_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.image_dir, self.image_files[idx])\n",
        "        label_path = os.path.join(self.label_dir, self.label_files[idx])\n",
        "\n",
        "        # Load image\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # Load label (e.g., parse YOLO format)\n",
        "        label = []  # Implement label loading\n",
        "        with open(label_path, \"r\") as f:\n",
        "            with line in f:\n",
        "                label.append(read_label(line))\n",
        "\n",
        "        # Apply transformations\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set = CustomDataset(os.path.join(DATASET_DIR, IMG_PATH_DICT['train']), os.path.join(DATASET_DIR, LABEL_PATH_DICT['train']))\n",
        "val_set = CustomDataset(os.path.join(DATASET_DIR, IMG_PATH_DICT['val']), os.path.join(DATASET_DIR, LABEL_PATH_DICT['val']))\n",
        "test_set = CustomDataset(os.path.join(DATASET_DIR, IMG_PATH_DICT['test']), os.path.join(DATASET_DIR, LABEL_PATH_DICT['test']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Inference"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "GboZnz_Zw5nr",
        "fxA2snOQxvUi",
        "0aOf7eIv2k-D",
        "n69tnCaI3JbF",
        "yYeBfdqg7Heh",
        "0AUfAZUyISdV",
        "kP2XzOm6O9Rg",
        "kamkbyYCe6B7"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
